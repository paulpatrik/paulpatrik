{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (42000, 32, 32) (42000,)\n",
      "Validation set (60000, 32, 32) (60000,)\n",
      "Test set (18000, 32, 32) (18000,)\n"
     ]
    }
   ],
   "source": [
    "# Open the file as readonly\n",
    "h5f = h5py.File('SVHN_single_grey1.h5', 'r')\n",
    "\n",
    "# Load the training, test and validation set\n",
    "X_train = h5f['X_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "y_test = h5f['y_test'][:]\n",
    "X_val = h5f['X_val'][:]\n",
    "y_val = h5f['y_val'][:]\n",
    "\n",
    "# Close this file\n",
    "h5f.close()\n",
    "\n",
    "print('Training set', X_train.shape, y_train.shape)\n",
    "print('Validation set', X_val.shape, y_val.shape)\n",
    "print('Test set', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#Randomly print an image and it's label\n",
    "plt.imshow(X_train[15000])\n",
    "plt.show()\n",
    "print(y_train[15000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D, Dense, Input, Dropout, Flatten, Activation, MaxPooling2D, AveragePooling2D, BatchNormalization\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras import backend as K\n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "K.set_image_dim_ordering('tf') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test,num_classes=10)\n",
    "y_val = tf.keras.utils.to_categorical(y_val,num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tf.keras.Sequential()\n",
    "\n",
    "#Flatten layer 32 x 32 = 1024 parameters\n",
    "model1.add(tf.keras.layers.Reshape((1024,), input_shape=(32,32,)))\n",
    "\n",
    "model1.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#First hidden layer\n",
    "model1.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "model1.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "model1.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model1.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "model1.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "\n",
    "model1.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "#Compile\n",
    "model1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 699,690\n",
      "Trainable params: 699,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 2s 43us/sample - loss: 1.8289 - acc: 0.3507 - val_loss: 1.2934 - val_acc: 0.5814\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.0555 - acc: 0.6649 - val_loss: 0.9147 - val_acc: 0.7117\n",
      "Epoch 3/5\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.8262 - acc: 0.7435 - val_loss: 0.7211 - val_acc: 0.7817\n",
      "Epoch 4/5\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.7061 - acc: 0.7820 - val_loss: 0.6532 - val_acc: 0.8011\n",
      "Epoch 5/5\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6248 - acc: 0.8075 - val_loss: 0.5922 - val_acc: 0.8201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2070e63eb38>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train,y_train,validation_data=(X_val,y_val), epochs=5, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5703 - acc: 0.8225 - val_loss: 0.5404 - val_acc: 0.8359\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5196 - acc: 0.8391 - val_loss: 0.5384 - val_acc: 0.8365\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4846 - acc: 0.8472 - val_loss: 0.4951 - val_acc: 0.8489\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.4567 - acc: 0.8575 - val_loss: 0.4623 - val_acc: 0.8597\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 0.4251 - acc: 0.8667 - val_loss: 0.4337 - val_acc: 0.8713\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3958 - acc: 0.8749 - val_loss: 0.4491 - val_acc: 0.8648\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3706 - acc: 0.8840 - val_loss: 0.4170 - val_acc: 0.8765\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3442 - acc: 0.8920 - val_loss: 0.3990 - val_acc: 0.8833\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3271 - acc: 0.8948 - val_loss: 0.3831 - val_acc: 0.8889\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.3075 - acc: 0.9021 - val_loss: 0.3600 - val_acc: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2070e63e9e8>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train,y_train,validation_data=(X_val,y_val), epochs=10, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 2s 43us/sample - loss: 1.6411 - acc: 0.4342 - val_loss: 1.1435 - val_acc: 0.6417\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.9638 - acc: 0.6982 - val_loss: 0.8511 - val_acc: 0.7360\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.7872 - acc: 0.7551 - val_loss: 0.7236 - val_acc: 0.7758\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6830 - acc: 0.7882 - val_loss: 0.6388 - val_acc: 0.8034\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6099 - acc: 0.8094 - val_loss: 0.5814 - val_acc: 0.8229\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5572 - acc: 0.8276 - val_loss: 0.5282 - val_acc: 0.8393\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5096 - acc: 0.8415 - val_loss: 0.4893 - val_acc: 0.8528\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4611 - acc: 0.8566 - val_loss: 0.4644 - val_acc: 0.8611\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4390 - acc: 0.8625 - val_loss: 0.4393 - val_acc: 0.8684\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.4100 - acc: 0.8735 - val_loss: 0.4709 - val_acc: 0.8579\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3797 - acc: 0.8805 - val_loss: 0.4140 - val_acc: 0.8796\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3540 - acc: 0.8881 - val_loss: 0.4049 - val_acc: 0.8808\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3353 - acc: 0.8940 - val_loss: 0.3909 - val_acc: 0.8856\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3091 - acc: 0.9020 - val_loss: 0.4067 - val_acc: 0.8817\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3137 - acc: 0.9000 - val_loss: 0.3895 - val_acc: 0.8856\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2882 - acc: 0.9071 - val_loss: 0.3865 - val_acc: 0.8897\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2614 - acc: 0.9164 - val_loss: 0.3460 - val_acc: 0.9039\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.2460 - acc: 0.9219 - val_loss: 0.3638 - val_acc: 0.8971\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2507 - acc: 0.9194 - val_loss: 0.3441 - val_acc: 0.9054\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.2364 - acc: 0.9245 - val_loss: 0.3440 - val_acc: 0.9052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x208c232a3c8>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train,y_train,validation_data=(X_val,y_val), epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Since changing the number of epochs doesn't help much with our validation loss, we can try changing the optimizer function</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new model\n",
    "tf.keras.backend.clear_session()\n",
    "model2 = tf.keras.Sequential()\n",
    "\n",
    "#Flatten layer 32 x 32 = 1024 parameters\n",
    "model2.add(tf.keras.layers.Reshape((1024,), input_shape=(32,32,)))\n",
    "\n",
    "model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#First hidden layer\n",
    "model2.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "model2.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "model2.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model2.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "model2.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "\n",
    "model2.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "#Compile\n",
    "adam = tf.keras.optimizers.Adam(lr=0.,decay=0.1)\n",
    "model2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/5\n",
      "42000/42000 [==============================] - 2s 42us/sample - loss: 1.7080 - acc: 0.4131 - val_loss: 1.2268 - val_acc: 0.6201\n",
      "Epoch 2/5\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.9777 - acc: 0.6973 - val_loss: 0.8491 - val_acc: 0.7401\n",
      "Epoch 3/5\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.7814 - acc: 0.7573 - val_loss: 0.7031 - val_acc: 0.7864\n",
      "Epoch 4/5\n",
      "42000/42000 [==============================] - 2s 37us/sample - loss: 0.6820 - acc: 0.7873 - val_loss: 0.6424 - val_acc: 0.8040\n",
      "Epoch 5/5\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6153 - acc: 0.8090 - val_loss: 0.5851 - val_acc: 0.8222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x208b46a8da0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,y_train,validation_data=(X_val,y_val), epochs=5, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.5493 - acc: 0.8283 - val_loss: 0.5636 - val_acc: 0.8277\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 1s 34us/sample - loss: 0.5161 - acc: 0.8402 - val_loss: 0.5182 - val_acc: 0.8425\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 2s 42us/sample - loss: 0.4746 - acc: 0.8505 - val_loss: 0.4674 - val_acc: 0.8590\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4332 - acc: 0.8648 - val_loss: 0.4334 - val_acc: 0.8698\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.4115 - acc: 0.8695 - val_loss: 0.4344 - val_acc: 0.8705\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3826 - acc: 0.8797 - val_loss: 0.4140 - val_acc: 0.8764\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3617 - acc: 0.8855 - val_loss: 0.4068 - val_acc: 0.8792\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.3441 - acc: 0.8907 - val_loss: 0.3800 - val_acc: 0.8897\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3104 - acc: 0.9015 - val_loss: 0.3702 - val_acc: 0.8912\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.3062 - acc: 0.9020 - val_loss: 0.3693 - val_acc: 0.8940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x208c22f9c88>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,y_train,validation_data=(X_val,y_val), epochs=10, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.2813 - acc: 0.9110 - val_loss: 0.3418 - val_acc: 0.9034\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 0.2608 - acc: 0.9173 - val_loss: 0.3379 - val_acc: 0.9046\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.2488 - acc: 0.9207 - val_loss: 0.3628 - val_acc: 0.9001\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.2312 - acc: 0.9259 - val_loss: 0.3245 - val_acc: 0.9106\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2243 - acc: 0.9285 - val_loss: 0.3295 - val_acc: 0.9100\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2221 - acc: 0.9288 - val_loss: 0.3460 - val_acc: 0.9051\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.2201 - acc: 0.9291 - val_loss: 0.3171 - val_acc: 0.9154\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.1964 - acc: 0.9372 - val_loss: 0.3344 - val_acc: 0.9117\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.1951 - acc: 0.9373 - val_loss: 0.3373 - val_acc: 0.9113\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.1885 - acc: 0.9398 - val_loss: 0.3244 - val_acc: 0.9170\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.1876 - acc: 0.9396 - val_loss: 0.3205 - val_acc: 0.9207\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.1634 - acc: 0.9479 - val_loss: 0.3145 - val_acc: 0.9215\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.1634 - acc: 0.9466 - val_loss: 0.3073 - val_acc: 0.9259\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.1506 - acc: 0.9520 - val_loss: 0.3468 - val_acc: 0.9157\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.1510 - acc: 0.9510 - val_loss: 0.3102 - val_acc: 0.9265\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.1508 - acc: 0.9517 - val_loss: 0.3103 - val_acc: 0.9291\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 0.1367 - acc: 0.9557 - val_loss: 0.3300 - val_acc: 0.9228\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.1427 - acc: 0.9542 - val_loss: 0.3200 - val_acc: 0.9288\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.1339 - acc: 0.9565 - val_loss: 0.3148 - val_acc: 0.9310\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.1280 - acc: 0.9590 - val_loss: 0.3158 - val_acc: 0.9313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x208c230f780>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,y_train,validation_data=(X_val,y_val), epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By editing the learning rate we were not able to reduce the validation loss. We can try using Dropout to delete unused nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 2s 45us/sample - loss: 2.3083 - acc: 0.1257 - val_loss: 2.2125 - val_acc: 0.1937\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 1.9529 - acc: 0.2931 - val_loss: 1.4474 - val_acc: 0.5116\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 1.4946 - acc: 0.4866 - val_loss: 1.1405 - val_acc: 0.6314\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 1.2864 - acc: 0.5792 - val_loss: 0.9915 - val_acc: 0.6923\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.1470 - acc: 0.6388 - val_loss: 0.8718 - val_acc: 0.7363\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.0556 - acc: 0.6713 - val_loss: 0.8033 - val_acc: 0.7580\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.9819 - acc: 0.6954 - val_loss: 0.7487 - val_acc: 0.7742\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.9318 - acc: 0.7137 - val_loss: 0.7154 - val_acc: 0.7850\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.8906 - acc: 0.7262 - val_loss: 0.6771 - val_acc: 0.7944\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8509 - acc: 0.7405 - val_loss: 0.6405 - val_acc: 0.8084\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8164 - acc: 0.7490 - val_loss: 0.6121 - val_acc: 0.8160\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.7875 - acc: 0.7619 - val_loss: 0.5976 - val_acc: 0.8207\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7602 - acc: 0.7680 - val_loss: 0.5692 - val_acc: 0.8295\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.7393 - acc: 0.7751 - val_loss: 0.5479 - val_acc: 0.8367\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7062 - acc: 0.7847 - val_loss: 0.5336 - val_acc: 0.8400\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6975 - acc: 0.7886 - val_loss: 0.5163 - val_acc: 0.8446\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6752 - acc: 0.7937 - val_loss: 0.5119 - val_acc: 0.8458\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6611 - acc: 0.7974 - val_loss: 0.4983 - val_acc: 0.8504\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6468 - acc: 0.8025 - val_loss: 0.4844 - val_acc: 0.8556\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6370 - acc: 0.8051 - val_loss: 0.4729 - val_acc: 0.8583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20775c49630>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model3 = tf.keras.Sequential()\n",
    "\n",
    "#Flatten layer 32 x 32 = 1024 parameters\n",
    "model3.add(tf.keras.layers.Reshape((1024,), input_shape=(32,32,)))\n",
    "\n",
    "model3.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#First hidden layer\n",
    "model3.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "model3.add(tf.keras.layers.Dropout(0.4))\n",
    "model3.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "model3.add(tf.keras.layers.Dropout(0.2))\n",
    "model3.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model3.add(tf.keras.layers.Dropout(0.2))\n",
    "model3.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "model3.add(tf.keras.layers.Dropout(0.2))\n",
    "model3.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "\n",
    "model3.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "#Compile\n",
    "adam = tf.keras.optimizers.Adam(lr=0.,decay=0.1)\n",
    "model3.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model3.fit(X_train,y_train,validation_data=(X_val,y_val), epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 2s 45us/sample - loss: 2.3057 - acc: 0.1188 - val_loss: 2.2263 - val_acc: 0.1632\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.7944 - acc: 0.3628 - val_loss: 1.2472 - val_acc: 0.6055\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 1.2914 - acc: 0.5802 - val_loss: 0.9694 - val_acc: 0.7012\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 1.1004 - acc: 0.6534 - val_loss: 0.8464 - val_acc: 0.7464\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.9979 - acc: 0.6876 - val_loss: 0.7758 - val_acc: 0.7666\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.9267 - acc: 0.7094 - val_loss: 0.7314 - val_acc: 0.7788\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.8635 - acc: 0.7338 - val_loss: 0.6672 - val_acc: 0.7990\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.8216 - acc: 0.7445 - val_loss: 0.6470 - val_acc: 0.8035\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7869 - acc: 0.7570 - val_loss: 0.6160 - val_acc: 0.8160\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7565 - acc: 0.7689 - val_loss: 0.5913 - val_acc: 0.8256\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.7284 - acc: 0.7734 - val_loss: 0.5591 - val_acc: 0.8329\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.7002 - acc: 0.7832 - val_loss: 0.5471 - val_acc: 0.8354\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 0.6914 - acc: 0.7841 - val_loss: 0.5382 - val_acc: 0.8388\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6667 - acc: 0.7935 - val_loss: 0.5225 - val_acc: 0.8451\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6472 - acc: 0.7995 - val_loss: 0.4920 - val_acc: 0.8496\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.6284 - acc: 0.8052 - val_loss: 0.4840 - val_acc: 0.8547\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.6147 - acc: 0.8101 - val_loss: 0.4637 - val_acc: 0.8600\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5998 - acc: 0.8137 - val_loss: 0.4540 - val_acc: 0.8640\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 0.5848 - acc: 0.8188 - val_loss: 0.4457 - val_acc: 0.8653\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 0.5846 - acc: 0.8171 - val_loss: 0.4347 - val_acc: 0.8709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2070044ffd0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model4 = tf.keras.Sequential()\n",
    "\n",
    "#Flatten layer 32 x 32 = 1024 parameters\n",
    "model4.add(tf.keras.layers.Reshape((1024,), input_shape=(32,32,)))\n",
    "\n",
    "model4.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#First hidden layer\n",
    "model4.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "model4.add(tf.keras.layers.Dropout(0.4))\n",
    "model4.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "model4.add(tf.keras.layers.Dropout(0.2))\n",
    "model4.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model4.add(tf.keras.layers.Dropout(0.2))\n",
    "model4.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "model4.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "\n",
    "model4.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "#Compile\n",
    "adam = tf.keras.optimizers.Adam(lr=0.1,decay=0.1)\n",
    "model4.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model4.fit(X_train,y_train,validation_data=(X_val,y_val), epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing Dropout gives undesired output. Trying with Relu Activation function. Athough all Dense layers already have Relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 60000 samples\n",
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 2s 39us/sample - loss: 14.4803 - acc: 0.1006 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 1s 27us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 2s 44us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 1s 36us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 1s 35us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 1s 29us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 1s 30us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 1s 28us/sample - loss: 14.4940 - acc: 0.1008 - val_loss: 14.5063 - val_acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x207025f9978>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model5 = tf.keras.Sequential()\n",
    "\n",
    "#Flatten layer 32 x 32 = 1024 parameters\n",
    "model5.add(tf.keras.layers.Reshape((1024,), input_shape=(32,32,)))\n",
    "\n",
    "model5.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "#First hidden layer\n",
    "model5.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.4))\n",
    "model5.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.2))\n",
    "model5.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.2))\n",
    "model5.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "model5.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "\n",
    "model5.add(tf.keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "#Compile\n",
    "adam = tf.keras.optimizers.Adam(lr=1,decay=0.3)\n",
    "model5.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model5.fit(X_train,y_train,validation_data=(X_val,y_val), epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.8788719e-09, 8.3746534e-07, 9.7289849e-08, 1.2970570e-06,\n",
       "       2.9906161e-08, 1.4262328e-09, 3.3988093e-10, 9.9999774e-01,\n",
       "       3.2280078e-11, 1.4649792e-08], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=model1.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[99])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 with simultaneous Dense layers with nodes having Relu Activation Function and  count changing by a factor of 2 in each subsequent layer without any dropout function has the highest accuracy in validation and the lowest validation loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
